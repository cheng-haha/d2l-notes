{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import pandas as pd \n",
    "import torch \n",
    "from torch import nn \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "# 在训练模式下计算 `X` 的均值和方差\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X)  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 基于位置的前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN( nn.Module ):\n",
    "    ''' 输入x( 批次 ， 时间步或者序列长度  ， 特征维度或者隐藏单元数 ) '''\n",
    "    def __init__( self , ffn_num_input , ffn_num_hiddens , ffn_num_outputs  , **kwargs ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear( ffn_num_input , ffn_num_hiddens )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear( ffn_num_hiddens , ffn_num_outputs )\n",
    "    \n",
    "    def forward( self , X ):\n",
    "        return self.dense2( self.relu( self.dense1( X ) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.ones( ( 2 ,3 ,4 ) )\n",
    "ffn = PositionWiseFFN( 4, 4 , 8 )\n",
    "ffn( test_tensor ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#但是我们实际上是要把输入的位置维度映射到相同的位置维度，保证输入和输出相同，这么做的原因我想可能是为网络加入非线性\n",
    "ffn = PositionWiseFFN(  4  , 4 , 4  )\n",
    "ffn( test_tensor ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 残差连接和层归一化AddNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm( nn.Module ):\n",
    "    def __init__( self , normlized_shape , dropout , **kwargs ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout( dropout )\n",
    "        self.layer_norm = nn.LayerNorm( normlized_shape )\n",
    "    def forward( self , X  ,Y  ):#X一般是输入，Y是当前网络层的输出\n",
    "        return self.layer_norm( self.dropout( Y ) + X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm( [3 ,4] , 0.5 )\n",
    "add_norm( test_tensor , test_tensor  ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们实现transformer编码器的单元块,每个单元块要保证输入和输出的shape一致,其中我们有一个加入残差连接和层归一化的多头注意力，一个\n",
    "# 同样加入残差和层归一化的基于位置的前馈网络。\n",
    "class EncoderBlock( nn.Module ):\n",
    "    ''' 首先我们应该清楚要实现自注意力，要保证多头注意力中的q,k,v保持一致，我们应该有这个tips在心里，但是d2l代码还是给分开写了'''\n",
    "    def __init__(self , query_size , key_size , value_size , num_hiddens,  norm_shape , \n",
    "                ffn_num_input , ffn_num_hiddens ,  num_heads  , dropout , use_bias = False,  **kwargs ):\n",
    "        super().__init__( **kwargs )\n",
    "        #注意的是这里使用的是遮蔽点击注意力机制\n",
    "        self.attention = d2l.MultiHeadAttention( key_size , query_size , value_size , num_hiddens ,num_heads , dropout , use_bias )\n",
    "        self.addnorm1 = AddNorm( norm_shape , dropout )\n",
    "        self.ffn = PositionWiseFFN( ffn_num_input , ffn_num_hiddens , num_hiddens )\n",
    "        self.addnorm2 = AddNorm( norm_shape , dropout )\n",
    "    \n",
    "    def forward( self , X , valid_lens ):\n",
    "        #记住valid_lens是遮蔽从当前位置向后所有的元素。比如一个分数向量是[1 ,2 ,3 ],valid_len为[1]，就是遮蔽从位置1向后的所有的元素\n",
    "        #那么分数向量就是[1, 0 ,0 ]\n",
    "        Y = self.addnorm1( X , self.attention( X , X , X , valid_lens ) )\n",
    "        return self.addnorm2( Y , self.ffn( Y ) )#( batch_size , query_size , num_hiddens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones( 2 , 100 , 24 )\n",
    "valid_lens = torch.tensor( [3 ,2 ] )\n",
    "encoder_block = EncoderBlock( 24 , 24 , 24 , 24 ,[100,24] , 24 , 48 , 8 ,  0.5  )\n",
    "encoder_block( X  , valid_lens ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder( d2l.Encoder ):\n",
    "    def __init__( self ,vocab_size , query_szie , key_size , value_size , num_hiddens , norm_shape , ffn_numm_input , ffn_num_hiddens,  \n",
    "                   num_heads , num_layers , dropout , use_bias = False , **kwargs  ):\n",
    "        super().__init__( )\n",
    "        self.hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding( vocab_size , num_hiddens )#这里注意一下使用了embedding将词表维度映射到num_hiddens维\n",
    "        self.pos_encoding = d2l.PositionalEncoding( num_hiddens , dropout )\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range( num_layers ):\n",
    "            #这个方法显然就是将当前网络加入到顺序层当中(name: str, module: Module | None)\n",
    "            self.blks.add_module( 'block'+str(i) , \n",
    "                EncoderBlock( query_szie , key_size , value_size , num_hiddens , norm_shape , \n",
    "                                ffn_numm_input , ffn_num_hiddens , num_heads , dropout , use_bias  )    )\n",
    "\n",
    "\n",
    "    def forward( self , X , valid_lens , *args ):\n",
    "        '''在大脑中回忆起整个网络的细节：输入(batch_size , num_steps , vocab_size )--->embedding--->PositionalEncoding\n",
    "            --->( AddNorm( MultiHeadAttention )--->AddNorm( PositionWiseFFN ) ) * N --->hidden_state '''\n",
    "        # 因为位置编码值在 -1 和 1 之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding( self.embedding( X ) * math.sqrt( self.hiddens ) )\n",
    "        #这里将权值进行保存\n",
    "        self.attention_weights  = [None]*len( self.blks )\n",
    "        for i,blk in enumerate( self.blks ):\n",
    "            X = blk( X , valid_lens )\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder( 200 , 24 , 24 , 24 , 24 , [ 100 , 24 ] , 24 ,  ffn_num_hiddens= 48 , num_heads=8 ,  num_layers=2 , dropout=0.5  )\n",
    "#这里是词表维度为200，实际上输入为( 2 ,100 )的话，我们使用独热编码为( 2 , 100 , 200 ),但是我们实际上使用了embedding，将200维的信息映射到了24维，起到了\n",
    "#降维的效果，当然，这只是embedding的一个优点而已，另外一个分布的优点也得记住\n",
    "encoder.eval()\n",
    "encoder(torch.ones( ( 2 , 100 ) , dtype=torch.long ) , valid_lens ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock( nn.Module ):\n",
    "    def __init__( self , query_size , key_size , value_size , num_hiddens , norm_shape , ffn_num_input , \n",
    "                ffn_num_hiddens , num_heads , dropout , i , **kwargs ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.i = i #这个i的意思表示在第几个DecoderBlock里\n",
    "        self.attention1 = d2l.MultiHeadAttention( \n",
    "            key_size , query_size , value_size , num_hiddens , num_heads , dropout\n",
    "        )\n",
    "        self.addnorm1 = AddNorm(norm_shape , dropout )\n",
    "        self.attention2 = d2l.MultiHeadAttention(\n",
    "            key_size , query_size , value_size , num_hiddens  , num_heads , dropout\n",
    "        )\n",
    "        self.addnorm2 = AddNorm( norm_shape , dropout )\n",
    "        self.ffn = PositionWiseFFN( ffn_num_input , ffn_num_hiddens , num_hiddens )\n",
    "        self.addnorm3 = AddNorm( norm_shape , dropout )\n",
    "\n",
    "    def forward( self , X , state ):\n",
    "        #state为一个三元列表\n",
    "        enc_outputs , enc_valid_lens = state[0] , state[1]        \n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:#如果是训练阶段，kv就是自己。注意：训练的过程我们是把完整的一句话传入进去，而在预测的过程中我们是逐个词元逐个词元\n",
    "                                    #按照时间步顺序进行传递\n",
    "            key_values = X\n",
    "        else:#如果是预测阶段，我们要将以往过去的词元拼接起来，还有一点需要注意，注意力机制当中，时间步是在轴1上的\n",
    "            key_values = torch.cat( (state[2][self.i] , X ) , axis = 1 )\n",
    "            # print( key_values.shape )\n",
    "        state[2][self.i] = key_values#我们知道：输入shape为多大，经过一个block之后的shape就为多大。假设当前为\n",
    "        if self.training:#如果是在训练的话,也就是说model.train()的时候，self.training是True,model.eval()的时候self.training就是False\n",
    "            batch_size , num_steps , _ = X.shape\n",
    "            \n",
    "            # dec_valid_lens的开头：( batch_size , num_steps )\n",
    "            # 其中每一行是[1,2 ,.....,num_steps]\n",
    "            #这一段我们可以参考‘注意力评分函数’这一节，传入的是二维张量的话，就是对单个批次的数据进行遮蔽。这里就是将qv乘得的矩阵进行遮蔽\n",
    "            #将未来的信息进行遮蔽，只保留当前时间步与过去时间步的注意力关系。之后我们进行softmax得到的进行当前时间步与过去时间步的注意力分数\n",
    "            #这个注意力分数与values乘得的张量就是遮蔽注意力机制\n",
    "            dec_valid_lens = torch.arange( 1 , num_steps+1  , device=X.device ).repeat( batch_size , 1 )\n",
    "        else:#预测过程之所以不需要遮蔽，就是因为训练过程我们是将整段话传入进去，预测过程我们是把decode_block的输出作为输入，一个一个词元进行拼接，\n",
    "             #如果使用逐时间步拼接的方式，那么是根本看不到未来的词元(信息)的\n",
    "            dec_valid_lens = None\n",
    "        #自注意力机制,带遮蔽\n",
    "        X2 = self.attention1( X , key_values , key_values , dec_valid_lens )\n",
    "        Y = self.addnorm1( X , X2 )\n",
    "        #encoder-decoder attention\n",
    "        #enc_outputs的开头：( batch_size , num_steps , num_hiddens )\n",
    "        Y2 = self.attention2( Y , enc_outputs , enc_outputs , enc_valid_lens )\n",
    "        Z = self.addnorm2( Y , Y2 )\n",
    "        return self.addnorm3( Z , self.ffn( Z ) )  , state\n",
    "        #假如当前是预测阶段，我们全部输入语句为“这是一只猫啊”，假设当前不看batch，当前时间步的输入的X为[是].shape=( 1,5 )，\n",
    "        #那么通过拼接过往信息的张量为[<begin> , 这 ].shape = (2 , 5 ), 也就是说X.shape=(1,5),key_values.shape = (2 , 5 ):\n",
    "        #1. Q*k的转置-----> (1,5 )*( 5 ,2 ) = (1 ,2 )\n",
    "        #2. softmax当前矩阵，并且我们发现不需要Mask,因为当前输入的X不包含未来的信息\n",
    "        #3. 与values(2,5)相乘----->( 1,2  )*(2,5)---->得到了当前时间步与过去全部时间步的注意力机制( 1,5 )\n",
    "        #4. 之后拿着这个矩阵(Q)与编码矩阵(K,V)(6,5)进行attention----->( 1 , 5 )*(5,6 )-----*v(6 ,5 )---->(1 , 5 )\n",
    "        #5. 经过ffn之后我们将线性变换的输入设置为与num_hiddens一致，最后得到的就是(1 , 5 ),这个张量去查询词汇表可以得到当前词元[一]\n",
    "        #6. 将当前词元[一]作为下一个时间步的输入，并且将[一]与原来的词元拼接得到key_value( 3 ,5 ),重复第一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 24]) torch.Size([2, 300, 24])\n"
     ]
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock( 24 , 24 , 24 , 24 , [100 , 24] , 24 , 48 , 8 , 0.5 , 0 )\n",
    "decoder_blk.eval()\n",
    "X = torch.ones( ( 2 , 100 , 24 ) )\n",
    "state = [ encoder_block( X , valid_lens ),  valid_lens , [torch.randn( 2, 100 , 24 )] ]\n",
    "decoder_blk( X , state )\n",
    "result = decoder_blk( X , state )\n",
    "print(result[0].shape ,  state[2][0].shape ) #我们可以看到经过两次传递(模拟一次100个时间步输入的时候两个decoder_block的过程)，假设原来的stat[2]当中有值，\n",
    "                                             #我们会累加过去注意力机制的kv，我估计这样可以看到更多信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange( 1, 10 + 1, device=d2l.try_gpu()).repeat(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder( d2l.AttentionDecoder ):\n",
    "    def __init__( self , vocab_size ,  query_size , key_size ,value_size , num_hiddens , \n",
    "                norm_shape , ffn_num_input , ffn_num_hiddens , num_heads , num_layers , dropout , **kwargs  ):\n",
    "        super().__init__( **kwargs )\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding( vocab_size , num_hiddens )\n",
    "        self.pos_encoding = d2l.PositionalEncoding( num_hiddens , dropout )\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range( num_layers ):#堆叠Decoder_block\n",
    "            self.blks.add_module(  \"block\"+str( i ) , \n",
    "                        DecoderBlock( query_size , key_size , value_size , num_hiddens , norm_shape , ffn_num_input , ffn_num_hiddens , \n",
    "                                        num_heads , dropout , i )#注意一下i的意思：第几个DecoderBlock\n",
    "            )\n",
    "        self.dense = nn.Linear( num_hiddens , vocab_size )#重新映射到词汇表大小当中，方便从词汇表当中提取词汇\n",
    "\n",
    "    def init_state( self , enc_outputs , enc_valid_lens , *args ):#这段函数的调用还是要参考EncoderDecoder的类方法当中，参看‘编码器和解码器.ipynb’\n",
    "        #返回的三元列表：[ 编码器输出( 隐藏状态信息 ) , 编码可用信息 ， 解码器每一个block的注意力参数 ]\n",
    "        return [ enc_outputs , enc_valid_lens , [None] * self.num_layers ]\n",
    "\n",
    "    def forward( self , X , state ):\n",
    "        X = self.pos_encoding( self.embedding( X )*math.sqrt( self.num_hiddens ) )\n",
    "        self._attention_weights = [ [None]*len( self.blks ) for _ in range( 2 )]#第一个存储MaskMutleHeadAttention的权值，第二个存储EncoderDecoderAttenion的权值\n",
    "        for i,blk in enumerate( self.blks ):\n",
    "            X,state = blk( X , state )\n",
    "            #遮蔽注意力机制\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights#这个attention_weights是每个decoder_block的点积注意力中的权值参数\n",
    "            #Encoder-Decoder注意力机制\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense( X ) ,state\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.032, 3629.8 tokens/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 262.1875 180.65625\" width=\"262.1875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-12-14T17:30:22.492563</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 262.1875 180.65625 \nL 262.1875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 143.1 \nL 245.44375 143.1 \nL 245.44375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 91.259539 143.1 \nL 91.259539 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m322b7761d1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"91.259539\" xlink:href=\"#m322b7761d1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 50 -->\n      <g transform=\"translate(84.897039 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 142.654276 143.1 \nL 142.654276 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"142.654276\" xlink:href=\"#m322b7761d1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(133.110526 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 194.049013 143.1 \nL 194.049013 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.049013\" xlink:href=\"#m322b7761d1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 150 -->\n      <g transform=\"translate(184.505263 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 245.44375 143.1 \nL 245.44375 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.44375\" xlink:href=\"#m322b7761d1\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 200 -->\n      <g transform=\"translate(235.9 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- epoch -->\n     <g transform=\"translate(132.565625 171.376563)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 50.14375 121.821081 \nL 245.44375 121.821081 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m27a35926ec\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m27a35926ec\" y=\"121.821081\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.05 -->\n      <g transform=\"translate(20.878125 125.6203)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 50.14375 80.901292 \nL 245.44375 80.901292 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m27a35926ec\" y=\"80.901292\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.10 -->\n      <g transform=\"translate(20.878125 84.70051)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe63dfddea3)\" d=\"M 50.14375 39.981502 \nL 245.44375 39.981502 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m27a35926ec\" y=\"39.981502\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.15 -->\n      <g transform=\"translate(20.878125 43.780721)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- loss -->\n     <g transform=\"translate(14.798437 84.807812)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pe63dfddea3)\" d=\"M 50.14375 13.377273 \nL 60.422697 52.388626 \nL 70.701645 79.960246 \nL 80.980592 96.648112 \nL 91.259539 108.50065 \nL 101.538487 115.343262 \nL 111.817434 120.531867 \nL 122.096382 124.691218 \nL 132.375329 127.51575 \nL 142.654276 126.567591 \nL 152.933224 129.227301 \nL 163.212171 131.485223 \nL 173.491118 133.005406 \nL 183.770066 134.293092 \nL 194.049013 133.071226 \nL 204.327961 133.885983 \nL 214.606908 134.797107 \nL 224.885855 136.766461 \nL 235.164803 136.247083 \nL 245.44375 136.922727 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 143.1 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 245.44375 143.1 \nL 245.44375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 143.1 \nL 245.44375 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 245.44375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe63dfddea3\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab),  query_size,key_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), query_size, key_size,  value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !,  bleu 1.000\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "he's calm . => il est calme .,  bleu 1.000\n",
      "i'm home . => je suis chez moi .,  bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
