{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torch import nn\r\n",
    "import torch \r\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def conv_block( input_channels , out_channels ):\r\n",
    "    return nn.Sequential( \r\n",
    "            nn.BatchNorm2d( input_channels ), nn.ReLU(),#这里使用的是归一化-激活-卷积的方式\r\n",
    "            nn.Conv2d(  input_channels , out_channels , kernel_size= 3 , padding=1 )#就是返回的特征图是原图大小\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class DenseBlock( nn.Module ):\r\n",
    "    def __init__( self , num_convs , input_channels , num_channels  ):\r\n",
    "        super().__init__()\r\n",
    "        layers= []\r\n",
    "        for i in range( num_convs ):\r\n",
    "            layers.append( conv_block(\r\n",
    "                 input_channels +num_channels* i , num_channels\r\n",
    "                 )#这里添加将输入通道与输出通道进行相加，比如说两个block，输入通道输出通道为3,10，\r\n",
    "                 #第一个block输出通道为13，那么为了保证第二个block的输入通道数正确，这里必须得加上1*num_channels\r\n",
    "                 #那么第二个block输入通道为13，输出通道为23.同理向后继续叠加。\r\n",
    "                 )\r\n",
    "        self.net = nn.Sequential( *layers )\r\n",
    "    def forward( self , x ):\r\n",
    "        for blk in self.net:\r\n",
    "            y = blk( x )\r\n",
    "            x = torch.cat(( x , y ) , dim= 1 )#在通道数上进行叠加\r\n",
    "        return x "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "blk = DenseBlock(2, 3, 10)\r\n",
    "X = torch.randn(4, 3, 8, 8)\r\n",
    "Y = blk(X)\r\n",
    "Y.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 增加一个过渡层，对特征图长度进行减半，也就是1*1的卷积，然后添加一个Maxpool或者Avgpool"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def transition_block( input_channels , output_channels ):\r\n",
    "    return nn.Sequential( \r\n",
    "            nn.BatchNorm2d( input_channels ), nn.ReLU() , \r\n",
    "            nn.Conv2d(  input_channels , output_channels ,  kernel_size=1 ),\r\n",
    "            nn.AvgPool2d( kernel_size=2 , stride=2 ),\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "blk = transition_block( 23 , 23 )\r\n",
    "blk(Y).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## densenet采用与resnet18一样的结构，采用4 个稠密块进行搭建.每个稠密块与残差快保持一致，都含有四个卷积层"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "b1 = nn.Sequential(\r\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\r\n",
    "    nn.BatchNorm2d(64), nn.ReLU(),\r\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# `num_channels`为当前的通道数\r\n",
    "num_channels, growth_rate = 64, 32\r\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\r\n",
    "blks = []\r\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\r\n",
    "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\r\n",
    "    # 上一个稠密块的输出通道数\r\n",
    "    num_channels += num_convs * growth_rate\r\n",
    "    # 在稠密块之间添加一个转换层，使通道数量减半\r\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\r\n",
    "        blks.append(transition_block(num_channels, num_channels // 2))\r\n",
    "        num_channels = num_channels // 2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "net = nn.Sequential(\r\n",
    "    b1, *blks,\r\n",
    "    nn.BatchNorm2d(num_channels), nn.ReLU(),\r\n",
    "    nn.AdaptiveMaxPool2d((1, 1)),\r\n",
    "    nn.Flatten(),\r\n",
    "    nn.Linear(num_channels, 10))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\r\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\r\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())#非常的莫名其妙，在第二个epoch跑飞，在第三个epoch又收敛\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training on  cuda:0\n",
      "num_batch:78 , avg_loss:2.61 , avg_accuracy:0.19\n",
      "num_batch:156 , avg_loss:1.90 , avg_accuracy:0.35\n",
      "num_batch:234 , avg_loss:1.52 , avg_accuracy:0.48\n",
      "num_batch:235 , avg_loss:1.52 , avg_accuracy:0.48\n",
      "epochs:0 ,test_acc:0.69 \n",
      "num_batch:78 , avg_loss:3.05 , avg_accuracy:0.11\n",
      "num_batch:156 , avg_loss:2.64 , avg_accuracy:0.12\n",
      "num_batch:234 , avg_loss:2.35 , avg_accuracy:0.16\n",
      "num_batch:235 , avg_loss:2.35 , avg_accuracy:0.16\n",
      "epochs:1 ,test_acc:0.30 \n",
      "num_batch:78 , avg_loss:1.55 , avg_accuracy:0.28\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_1372/2280015974.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data_fashion_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_No_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\CONDA\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36mtrain_No_image\u001b[1;34m(net, train_iter, test_iter, num_epochs, lr, device, num_print)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0moptimzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m  \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[0mtrain_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CONDA\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mcmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "4e3237dc568d8c012c4be0ad63f07931f6897ff43d3b726284ebc51bc8854128"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}