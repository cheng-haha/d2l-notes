{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **首先NiN网的思路非常有趣。在像alex和vgg等网络中，我们将最后卷积层的输出与全连接层进行连接，这会产生非常多的参数，参数太多也是导致过拟合的关键。NiN网络可以解决这样的问题。在一个nin块中，我们往往使用两个1*1的卷积层对每个通道上的像素进行一个提取，这样卷积完之后输出的每个特征点就是输入的每一个通道上的对应位置的像素的信息。之后，经过多个NiN块之后，最关键的一点来了，我们将最后输出的特征维度进行自适应平均到 1 * 1 ,之后reshape到二维，将输出的通道数视为不同的特征。**\r\n",
    "* **NiN块由一个普通的卷积层和两个1*1核大小的卷积层构成。普通的卷积层进行不同特征的提取，1 * 1的卷积层进行不同通道的信息集合，之后输入激活函数进行非线性输出**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "batch_size = 128\r\n",
    "train_iter , test_iter = d2l.load_data_fashion_mnist( batch_size ,resize= 224 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "def NiN_block( input_channels   , out_channels ,  kernel_size ,  strides ,  padding ):\r\n",
    "    return( nn.Sequential(  \r\n",
    "                            nn.Conv2d( input_channels , out_channels , kernel_size , strides , padding ),\r\n",
    "                            nn.ReLU(),\r\n",
    "                            nn.Conv2d( out_channels , out_channels ,kernel_size = 1 ), nn.ReLU(),\r\n",
    "                            nn.Conv2d( out_channels , out_channels , kernel_size = 1 ),  nn.ReLU()\r\n",
    "\r\n",
    "      )\r\n",
    "      )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "net = nn.Sequential( \r\n",
    "    NiN_block( 1,96,kernel_size= 11,strides= 4,padding=0 ),\r\n",
    "    nn.MaxPool2d( kernel_size=3 , stride = 2 ),\r\n",
    "    NiN_block( 96 , 256 , kernel_size=5,  strides=1 ,padding= 2 ),\r\n",
    "    nn.MaxPool2d( kernel_size=3 , stride=2  ),\r\n",
    "    NiN_block( 256 , 384 , kernel_size=3 , strides=1, padding= 1 ),\r\n",
    "    nn.MaxPool2d( kernel_size=3 , stride=2 ),\r\n",
    "    nn.Dropout( 0.5 ),\r\n",
    "    NiN_block( 384 , 10 , kernel_size=3 , strides=1, padding=1),\r\n",
    "    nn.AdaptiveAvgPool2d( (1,1)),#将输出的特征输出为1*1\r\n",
    "    nn.Flatten()#之后展开为Batchsize*10\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "x = torch.rand( size = (1 , 1, 224 , 244 ))\r\n",
    "for layer in net:\r\n",
    "    x = layer(x)\r\n",
    "    print( layer.__class__.__name__ , 'output_size:' , x.shape )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential output_size: torch.Size([1, 96, 54, 59])\n",
      "MaxPool2d output_size: torch.Size([1, 96, 26, 29])\n",
      "Sequential output_size: torch.Size([1, 256, 26, 29])\n",
      "MaxPool2d output_size: torch.Size([1, 256, 12, 14])\n",
      "Sequential output_size: torch.Size([1, 384, 12, 14])\n",
      "MaxPool2d output_size: torch.Size([1, 384, 5, 6])\n",
      "Dropout output_size: torch.Size([1, 384, 5, 6])\n",
      "Sequential output_size: torch.Size([1, 10, 5, 6])\n",
      "AdaptiveAvgPool2d output_size: torch.Size([1, 10, 1, 1])\n",
      "Flatten output_size: torch.Size([1, 10])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "len(train_iter) , len(train_iter)//5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(469, 93)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "def train_simple_NiN( net , train_iter ,  test_iter , num_epochs , lr , device ):\r\n",
    "    print('training on ', device )\r\n",
    "    net.to( device )\r\n",
    "    loss = nn.CrossEntropyLoss()\r\n",
    "    optimzer = torch.optim.Adam( net.parameters() , lr )\r\n",
    "    num_batch = len( train_iter )\r\n",
    "    for epoch in range( num_epochs ):\r\n",
    "        #存储多个批次的loss,准确个数，和总样本数\r\n",
    "        metrics = d2l.Accumulator(3)\r\n",
    "        for i , ( X,y) in enumerate( train_iter ):\r\n",
    "            X = X.to( device )\r\n",
    "            y = y.to( device )\r\n",
    "            optimzer.zero_grad()\r\n",
    "            y_hat = net( X )\r\n",
    "            l = loss( y_hat , y )\r\n",
    "            l.backward()\r\n",
    "            optimzer.step()\r\n",
    "            with torch.no_grad():\r\n",
    "                metrics.add( l*X.shape[0] , d2l.accuracy( y_hat , y ) ,  y.numel() )\r\n",
    "            train_loss = metrics[0]/metrics[2]\r\n",
    "            train_acc  = metrics[1]/metrics[2]\r\n",
    "            if (i+1) % (num_batch // 3 ) == 0 or i == num_batch-1:\r\n",
    "\r\n",
    "                print( f'num_batch:{i+1} , avg_loss:{train_loss:.2f} , avg_accuracy:{train_acc:.2f}' )\r\n",
    "        test_acc  = d2l.evaluate_accuracy_gpu( net , test_iter , device )\r\n",
    "        print( f'epochs:{epoch} ,test_acc:{test_acc:.2f} ')\r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "self_lr , self_num_epochs = 0.001 , 10\r\n",
    "train_simple_NiN( net , train_iter , test_iter , num_epochs=self_num_epochs ,lr=self_lr , device=d2l.try_gpu() )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training on  cuda:0\n",
      "num_batch:93 , avg_loss:2.19 , avg_accuracy:0.17\n",
      "num_batch:186 , avg_loss:1.93 , avg_accuracy:0.29\n",
      "num_batch:279 , avg_loss:1.70 , avg_accuracy:0.38\n",
      "num_batch:372 , avg_loss:1.54 , avg_accuracy:0.43\n",
      "num_batch:465 , avg_loss:1.42 , avg_accuracy:0.48\n",
      "num_batch:469 , avg_loss:1.42 , avg_accuracy:0.48\n",
      "epochs:0 ,test_acc:0.71 \n",
      "num_batch:93 , avg_loss:0.81 , avg_accuracy:0.71\n",
      "num_batch:186 , avg_loss:0.78 , avg_accuracy:0.72\n",
      "num_batch:279 , avg_loss:0.75 , avg_accuracy:0.73\n",
      "num_batch:372 , avg_loss:0.74 , avg_accuracy:0.74\n",
      "num_batch:465 , avg_loss:0.72 , avg_accuracy:0.74\n",
      "num_batch:469 , avg_loss:0.72 , avg_accuracy:0.74\n",
      "epochs:1 ,test_acc:0.78 \n",
      "num_batch:93 , avg_loss:0.62 , avg_accuracy:0.77\n",
      "num_batch:186 , avg_loss:0.61 , avg_accuracy:0.78\n",
      "num_batch:279 , avg_loss:0.60 , avg_accuracy:0.79\n",
      "num_batch:372 , avg_loss:0.59 , avg_accuracy:0.79\n",
      "num_batch:465 , avg_loss:0.58 , avg_accuracy:0.79\n",
      "num_batch:469 , avg_loss:0.58 , avg_accuracy:0.79\n",
      "epochs:2 ,test_acc:0.81 \n",
      "num_batch:93 , avg_loss:0.52 , avg_accuracy:0.81\n",
      "num_batch:186 , avg_loss:0.51 , avg_accuracy:0.82\n",
      "num_batch:279 , avg_loss:0.52 , avg_accuracy:0.82\n",
      "num_batch:372 , avg_loss:0.51 , avg_accuracy:0.82\n",
      "num_batch:465 , avg_loss:0.50 , avg_accuracy:0.82\n",
      "num_batch:469 , avg_loss:0.50 , avg_accuracy:0.82\n",
      "epochs:3 ,test_acc:0.82 \n",
      "num_batch:93 , avg_loss:0.48 , avg_accuracy:0.83\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_7080/500672256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mself_lr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself_num_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_simple_NiN\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_num_epochs\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_lr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_7080/1160016714.py\u001b[0m in \u001b[0;36mtrain_simple_NiN\u001b[1;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0moptimzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m  \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtrain_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CONDA\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mcmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr , num_epochs = 0.001 , 10\r\n",
    "d2l.train_ch6( net , train_iter ,test_iter , num_epochs , lr , d2l.try_gpu() )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "4e3237dc568d8c012c4be0ad63f07931f6897ff43d3b726284ebc51bc8854128"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}