{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch \r\n",
    "from d2l import torch as d2l\r\n",
    "from torch import nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def vgg_block( num_convs , input_channels , out_channels ):\r\n",
    "    layer = []\r\n",
    "    for _ in range( num_convs ):\r\n",
    "        layer.append( nn.Conv2d( input_channels , out_channels , kernel_size=3 ,padding=1 ) )\r\n",
    "        layer.append( nn.ReLU() )\r\n",
    "        input_channels = out_channels\r\n",
    "    layer.append( nn.MaxPool2d( kernel_size=2 , stride=2 ))\r\n",
    "    return nn.Sequential( *layer ) #返回一个vggblock块"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#构建一个元组，每一个小元组对应的是两个元素，第一个元素对应一个块中卷积层的个数，第二个元素对应的是一个块的输出通道\r\n",
    "conv_arch = ( (1 , 64) , ( 1 , 128) , (2,256) , ( 2 ,512 ) , ( 2 , 512 ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def vggnet( conv_arch  ):\r\n",
    "    conv_block = []\r\n",
    "    input_channels = 1\r\n",
    "    for ( num_convs , output_channels ) in conv_arch:\r\n",
    "        conv_block.append( vgg_block( num_convs , input_channels , output_channels  ) )\r\n",
    "        input_channels = output_channels\r\n",
    "    return nn.Sequential( *conv_block , nn.Flatten(),#batchsize*512*7*7\r\n",
    "                           nn.Linear( output_channels*7*7,  4096) , nn.ReLU() , nn.Dropout( p=0.5),\r\n",
    "                           nn.Linear( 4096 , 4096 ),nn.ReLU( ) ,nn.Dropout( p=0.5 ),\r\n",
    "                           nn.Linear( 4096 , 10 ) ) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net = vggnet( conv_arch )\r\n",
    "x = torch.rand( 1,1,224,224)\r\n",
    "for layer in net:\r\n",
    "    x = layer( x )\r\n",
    "    print( layer.__class__.__name__ , 'output_size:' , x.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#现在就尝试将通道数减小，毕竟这种通道训练起来挺慢的\r\n",
    "redio = 4#这里注意要是2的倍数，不能奇数\r\n",
    "small_convs_arch = [ ( item[0] , item[1]//4) for item in conv_arch]\r\n",
    "small_convs_arch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 32\r\n",
    "train_iter , test_iter  = d2l.load_data_fashion_mnist( batch_size=batch_size ,resize=224 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "lr ,  num_epochs = 0.001 , 10\r\n",
    "d2l.train_ch6( net , train_iter , test_iter , num_epochs , lr , d2l.try_gpu(i=1) )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "4e3237dc568d8c012c4be0ad63f07931f6897ff43d3b726284ebc51bc8854128"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}