{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrd2( x , k ):\n",
    "    h , w = k.shape\n",
    "    y = torch.zeros( x.shape[0]-h+1 , x.shape[1]-w+1 )\n",
    "    for i in range( y.shape[0] ):\n",
    "        for j in range( y.shape[1] ):\n",
    "            y[i,j] = ( x[ i : i+h , j : j+w ] * k).sum()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]]),\n",
       " tensor([[1., 0.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " tensor([[ 5.,  7.,  9.],\n",
       "         [13., 15., 17.],\n",
       "         [21., 23., 25.]], grad_fn=<CopySlices>))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(16).reshape( 4,4)\n",
    "k = torch.tensor( [[1,0],[0,1] ] ,dtype=torch.float32, requires_grad=True )\n",
    "x,k,corrd2( x,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cov2d_test( nn.Module ):\n",
    "    def __init__( self  , *kernel_size ):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter( torch.ones( kernel_size ) ,requires_grad= True)\n",
    "        # self.bias = nn.Parameter( torch.zeros( 1 ) , requires_grad= True) #在神经网络中卷积是在求和，所以只需要一个偏置\n",
    "    def forward( self , x ):\n",
    "        return corrd2( x , self.weight ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3],\n",
       "         [4, 5, 6, 7]]),\n",
       " tensor([[10., 14., 18.]], grad_fn=<CopySlices>),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = Cov2d_test( 2,2 )\n",
    "x = torch.arange( 8).reshape( 2 , 4 )\n",
    "x , conv1( x ) , conv1.weight.data,conv1.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积迭代实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Cov2d_test( nn.Module ):\n",
    "    def __init__( self  , *kernel_size ):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter( torch.ones( kernel_size ) ,requires_grad= True)\n",
    "        # self.bias = nn.Parameter( torch.zeros( 1 ) , requires_grad= True) #在神经网络中卷积是在求和，所以只需要一个偏置\n",
    "    def forward( self , x ):\n",
    "        return corrd2( x , self.weight ) \n",
    "cov1 = Cov2d_test( 2,2 )\n",
    "cov1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3],\n",
       "         [4, 5, 6, 7]]),\n",
       " tensor([[5., 7., 9.]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(8).reshape( 2,4 )\n",
    "y = corrd2(x , torch.Tensor( [[1,0],[0,1] ]))\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:9 , loss:0.4637046456336975\n",
      "batch:19 , loss:0.41661059856414795\n",
      "batch:29 , loss:0.3845173120498657\n",
      "batch:39 , loss:0.35489803552627563\n",
      "batch:49 , loss:0.3275596797466278\n",
      "batch:59 , loss:0.30232682824134827\n",
      "batch:69 , loss:0.27903860807418823\n",
      "batch:79 , loss:0.2575428783893585\n",
      "batch:89 , loss:0.23770400881767273\n",
      "batch:99 , loss:0.21939361095428467\n",
      "batch:109 , loss:0.20249325037002563\n",
      "batch:119 , loss:0.1868947148323059\n",
      "batch:129 , loss:0.17249828577041626\n",
      "batch:139 , loss:0.1592099815607071\n",
      "batch:149 , loss:0.14694596827030182\n",
      "batch:159 , loss:0.13562601804733276\n",
      "batch:169 , loss:0.12517939507961273\n",
      "batch:179 , loss:0.115536168217659\n",
      "batch:189 , loss:0.10663630068302155\n",
      "batch:199 , loss:0.09842219948768616\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    y_hat = cov1(x)\n",
    "    l = (y_hat-y)**2\n",
    "    cov1.zero_grad()\n",
    "    l.sum().backward()\n",
    "    cov1.weight.data -= 0.001*cov1.weight.grad\n",
    "    if (i+1)%10 ==0:\n",
    "        print(f'batch:{i} , loss:{l.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.7513, 6.9689, 9.1866]], grad_fn=<CopySlices>),\n",
       " Parameter containing:\n",
       " tensor([[0.6710, 0.6244],\n",
       "         [0.4845, 0.4378]], requires_grad=True))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y =corrd2(x , cov1.weight)\n",
    "pre_y,cov1.weight#显然我们当时设置的权值是[[1,0],[0,1]，而这里的权值是[[0.6710, 0.6244],[0.4845, 0.4378]]，显然过拟合了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones( (6,8))\n",
    "x[:,2:6]=0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]),\n",
       " torch.Size([6, 7]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.tensor( [[1. , -1. ]])\n",
    "y = corrd2( x,k)\n",
    "y,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "batch:0 , loss:25.960784912109375\n",
      "batch:1 , loss:20.09854507446289\n",
      "batch:2 , loss:15.563437461853027\n",
      "batch:3 , loss:12.052184104919434\n",
      "batch:4 , loss:9.333189010620117\n",
      "batch:5 , loss:7.227618217468262\n",
      "batch:6 , loss:5.597066879272461\n",
      "batch:7 , loss:4.334368705749512\n",
      "batch:8 , loss:3.3565356731414795\n",
      "batch:9 , loss:2.5993010997772217\n"
     ]
    }
   ],
   "source": [
    "cov2 = nn.Conv2d( 1,1,kernel_size=(1,2) , bias=False )\n",
    "x = x.reshape(1,1,6,8)\n",
    "y = y.reshape( (1,1,6,7))\n",
    "print( cov2.weight.grad )\n",
    "for i in range( 10 ):\n",
    "    y_hat = cov2( x )\n",
    "    l = (y_hat-y)**2\n",
    "    cov2.zero_grad()\n",
    "    l.sum().backward()\n",
    "    cov2.weight.data[:] -= 0.01*cov2.weight.grad\n",
    "    print( f'batch:{i} , loss:{l.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 7.154\n",
      "batch 4, loss 1.467\n",
      "batch 6, loss 0.355\n",
      "batch 8, loss 0.104\n",
      "batch 10, loss 0.036\n"
     ]
    }
   ],
   "source": [
    "# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "# 其中批量大小和通道数都为1\n",
    "X = x.reshape((1, 1, 6, 8))\n",
    "Y = y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # 迭代卷积核\n",
    "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'batch {i+1}, loss {l.sum():.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('STR-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50d5be1d15b8a64130c39dd1bec9da8c7a8ee88a4330e33eef1c05faa50f91e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
