{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4425],\n",
       "         [0.4425]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0718, -0.6553,  0.0997,  0.5128,  0.1804, -1.3132, -0.4703,  0.5067],\n",
       "         [-0.0718, -0.6553,  0.0997,  0.5128,  0.1804, -1.3132, -0.4703,  0.5067]],\n",
       "        grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential( nn.Linear( 4,8) , nn.ReLU() , nn.Linear( 8 ,1 ) )\n",
    "x  = torch.ones( 2,4 )\n",
    "net( x ) , net[0](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4]) Parameter containing:\n",
      "tensor([[-0.0276,  0.1369, -0.2098,  0.3570],\n",
      "        [ 0.2935, -0.4089, -0.4007,  0.1465],\n",
      "        [ 0.2554, -0.3449, -0.0934, -0.2119],\n",
      "        [-0.2409,  0.4620, -0.2183,  0.3321],\n",
      "        [ 0.1007, -0.1509,  0.0962,  0.4125],\n",
      "        [-0.4971, -0.2493, -0.3001,  0.1739],\n",
      "        [-0.3087, -0.0322,  0.3761, -0.4283],\n",
      "        [ 0.4632, -0.0415, -0.0617,  0.2544]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print( net[0].weight.shape , net[0].weight )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **这里就会有一个问题，我们之前做的相乘都是X@Weight+bias ,但是在nn.Linear里不是这样做的，因为显然这个weight矩阵是8 * 4 ,X是2 * 4，显然不是X@Weight这么简单**\n",
    "* 通过阅读nn.Linear的源码知道了在linear中做了这个操作ret = torch.addmm(bias, input, weight.t())，具体查看functional的linear函数，所以可知在线性层中是X@Weight.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0718, -0.6553,  0.0997,  0.5128,  0.1804, -1.3132, -0.4703,  0.5067],\n",
       "        [-0.0718, -0.6553,  0.0997,  0.5128,  0.1804, -1.3132, -0.4703,  0.5067]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mm( net[0].weight.detach().T ) + net[0].bias.detach()  #结果正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0276,  0.1369, -0.2098,  0.3570],\n",
       "        [ 0.2935, -0.4089, -0.4007,  0.1465],\n",
       "        [ 0.2554, -0.3449, -0.0934, -0.2119],\n",
       "        [-0.2409,  0.4620, -0.2183,  0.3321],\n",
       "        [ 0.1007, -0.1509,  0.0962,  0.4125],\n",
       "        [-0.4971, -0.2493, -0.3001,  0.1739],\n",
       "        [-0.3087, -0.0322,  0.3761, -0.4283],\n",
       "        [ 0.4632, -0.0415, -0.0617,  0.2544]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.1523, -0.2268,  0.2209,  0.0400, -0.0794, -0.2174, -0.1404,  0.3296]])),\n",
       "             ('bias', tensor([0.2472]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1] #所以在torch里要将激活函数算作一层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([8, 4])\n",
      "0.bias torch.Size([8])\n",
      "2.weight torch.Size([1, 8])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for block in  net.state_dict():\n",
    "    print( block , net.state_dict()[block].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=8, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.named_modules())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('STR-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50d5be1d15b8a64130c39dd1bec9da8c7a8ee88a4330e33eef1c05faa50f91e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
