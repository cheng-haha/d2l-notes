{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\r\n",
    "import torch\r\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "# 观察test_w是否是一个列向量\r\n",
    "X = torch.arange(1,5,dtype=torch.float).reshape(2,2)\r\n",
    "print(X , X.dtype )\r\n",
    "test_w = torch.Tensor([[1.],[1.]])\r\n",
    "result = torch.matmul( X , test_w )\r\n",
    "print( result )\r\n",
    "test_w.t()\r\n",
    "#如果只有一个轴的向量就是列向量"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]]) torch.float32\n",
      "tensor([[3.],\n",
      "        [7.]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **range应该是一个可迭代对象**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "a = iter( range(10) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "next( a )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **list能否对list直接做一个随机提取？**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "# 随机取特征的单行数据，设置一个indics的指标进行随机选取\r\n",
    "fetures = torch.arange(  1,5 ,dtype= torch.float ).reshape( 2 , 2)\r\n",
    "print( fetures )\r\n",
    "indics = [0,1]\r\n",
    "random.shuffle(indics)\r\n",
    "print( indics )\r\n",
    "indics = torch.tensor( indics )\r\n",
    "print( indics )\r\n",
    "fetures , fetures[indics]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "[1, 0]\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [3., 4.]]),\n",
       " tensor([[3., 4.],\n",
       "         [1., 2.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "test_one = [222,333 , 444 ]\r\n",
    "indics_list = [ 0 , 1 ,2]\r\n",
    "test_one[indics_list]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_18156/2273883688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m222\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m333\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m444\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindics_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_one\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindics_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_one = torch.tensor( [222,333 , 444 ] )\r\n",
    "indics_list = torch.tensor( [ 0 , 1 ,2] )\r\n",
    "test_one[indics_list]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**显然，由上下两段代码可知，list是不能由list进行提取，而tensor可以**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **关于TensorDatasets和Dataloader**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "a = torch.tensor([[11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99]])\r\n",
    "b = torch.tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\r\n",
    "train_ids = TensorDataset(a, b) \r\n",
    "print( train_ids[:5])\r\n",
    "#所以TensorDataset就是将两个数据进行一个打包，往往是特征与对应的标签进行一个绑定"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[11, 22, 33],\n",
      "        [44, 55, 66],\n",
      "        [77, 88, 99],\n",
      "        [11, 22, 33],\n",
      "        [44, 55, 66]]), tensor([0, 1, 2, 0, 1]))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# 循环取数据\r\n",
    "for train_data , train_laybers in train_ids:\r\n",
    "    print( train_data , train_laybers)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "train_loader = DataLoader(dataset=train_ids, batch_size=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "next(  iter( train_loader ) )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[11, 22, 33],\n",
       "         [44, 55, 66],\n",
       "         [77, 88, 99],\n",
       "         [11, 22, 33]]),\n",
       " tensor([0, 1, 2, 0])]"
      ]
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **观察1.4torch的normal是否仍然像numpy一样可用**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.normal(0, 0.01,(2,1), requires_grad=True)#在1.1版本会报错"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.tensor([2., 1.], requires_grad=True)\r\n",
    "y = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\r\n",
    "\r\n",
    "z = torch.mm(x.view(1, 2), y)\r\n",
    "print(f\"z:{z}\")\r\n",
    "z.backward(torch.Tensor([[1., 0]]))\r\n",
    "print(f\"x.grad: {x.grad}\")\r\n",
    "print(f\"y.grad: {y.grad}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.tensor([1.1], requires_grad=True)\r\n",
    "b = a * 2\r\n",
    "b.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "b.add_(2)\r\n",
    "print(a.grad , a.grad_fn , b.grad , b.grad_fn )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.tensor([1.1], requires_grad=True)\r\n",
    "b = a * 2\r\n",
    "b.requires_grad_()\r\n",
    "b.backward(retain_graph=True)\r\n",
    "print(b , a.grad,  b.grad_fn)\r\n",
    "# with torch.no_grad():\r\n",
    "#     a.add_(2)\r\n",
    "b , a , a.grad , b.grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "b.mul_(2)\r\n",
    "b.backward(retain_graph=True)\r\n",
    "print( a.grad , b.grad , b.grad_fn)#显然出现了梯度累加"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "b.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "b,b.grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = torch.tensor( [1.] , requires_grad= True )\r\n",
    "a = torch.add( X , 1 )**2\r\n",
    "a.requires_grad_()\r\n",
    "b = torch.add( X , 2 )\r\n",
    "\r\n",
    "y = a * b\r\n",
    "X , a , b , y "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# y.backward()\r\n",
    "print(a , a.grad , X.grad )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "w= torch.Tensor([1,1]).requires_grad_()\r\n",
    "b= torch.Tensor([1]).requires_grad_()\r\n",
    "w,b"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.ones( 2  , requires_grad= True ) \r\n",
    "# x.requires_grad_()\r\n",
    "print(x.requires_grad)\r\n",
    "y = torch.matmul(x , w) +b\r\n",
    "y.sum().backward()\r\n",
    "y , w.grad , x.grad , b.grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ** for a,b in list**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "ls = [[1,2] , [3,4]]\r\n",
    "for a, b in ls :\r\n",
    "    print( a,b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 2\n",
      "3 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "y = torch.tensor([0, 2])\r\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\r\n",
    "y , y_hat,y_hat[[0, 1], y] #第一参数取到第0个元素[0.1, 0.3, 0.6]和第1个元素[0.3, 0.2, 0.5]，之后由y这个列表，对前面对应的元素一一对应\r\n",
    "                           #取值，也就是说对0个元素取第0个值，对第1个元素取第2个值"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0, 2]),\n",
       " tensor([[0.1000, 0.3000, 0.6000],\n",
       "         [0.3000, 0.2000, 0.5000]]),\n",
       " tensor([0.1000, 0.5000]))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "y = torch.tensor([0, 2 ,0])\r\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\r\n",
    "y , y_hat,y_hat[[0, 1], y] #显然多加了一个参数是出bug了，因为后一个列表与前一个列表的取值不匹配"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [2], [3]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_9912/2121677626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [2], [3]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "4e3237dc568d8c012c4be0ad63f07931f6897ff43d3b726284ebc51bc8854128"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}